{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sentence-transformers torch datasets\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-05T06:19:13.734351Z","iopub.execute_input":"2024-12-05T06:19:13.734737Z","iopub.status.idle":"2024-12-05T06:19:26.819560Z","shell.execute_reply.started":"2024-12-05T06:19:13.734701Z","shell.execute_reply":"2024-12-05T06:19:26.818258Z"}},"outputs":[{"name":"stdout","text":"Collecting sentence-transformers\n  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0+cpu)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.45.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.25.1)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nDownloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-3.3.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset\nfrom torch.utils.data import DataLoader\nfrom sentence_transformers import InputExample\n\n# Load your dataset (replace with your dataset path or use dummy data)\ndata = [\n    {\"anchor\": \"Bali\", \"positive\": \"John went to Bali for vacation\", \"negative\": \"John went to Paris for vacation\"},\n    {\"anchor\": \"Paris\", \"positive\": \"John went to Paris for vacation\", \"negative\": \"John went to Bali for vacation\"}\n]\n\n# Convert to InputExample format\ntrain_examples = [\n    InputExample(texts=[item[\"anchor\"], item[\"positive\"], item[\"negative\"]])\n    for item in data\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T06:19:26.822048Z","iopub.execute_input":"2024-12-05T06:19:26.822513Z","iopub.status.idle":"2024-12-05T06:19:49.854864Z","shell.execute_reply.started":"2024-12-05T06:19:26.822464Z","shell.execute_reply":"2024-12-05T06:19:49.853886Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer, losses, models\nfrom sentence_transformers import LoggingHandler\nimport logging\n\n# Logging for progress tracking\nlogging.basicConfig(\n    format='%(asctime)s - %(message)s',\n    level=logging.INFO,\n    handlers=[LoggingHandler()]\n)\n\n# Load pre-trained model\nmodel_name = \"sentence-transformers/all-mpnet-base-v2\"\nmodel = SentenceTransformer(model_name)\n\n# Define the dataloader\ntrain_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n\n# Define the loss function\ntrain_loss = losses.TripletLoss(model)\n\n# Fine-tune the model\nmodel.fit(\n    train_objectives=[(train_dataloader, train_loss)],\n    epochs=30,\n    warmup_steps=100,\n    output_path=\"output/contrastive-mpnet\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T06:19:49.856044Z","iopub.execute_input":"2024-12-05T06:19:49.856650Z","iopub.status.idle":"2024-12-05T06:22:42.892573Z","shell.execute_reply.started":"2024-12-05T06:19:49.856618Z","shell.execute_reply":"2024-12-05T06:22:42.888988Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f388c13c54f840da9c60e1760e1b4c3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e578d3238d545ba808e9361c23ba2e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c187706ca4a54139b2710fcbda4b71a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f970815c7a543c7b219c7fc604b9134"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"649ff961f917467c8277fa269b57cdd7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0855e1a619f94518b67c59d1b838f76f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4755f41240a4e6bbfa0c6fe414a8f81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c104c21d5024f439b63617096297bc8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ebb2e5a6e6742639c0c0717de6a263a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a121cce007194e0fa5b73f70673fec6e"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5eee1c6cfe134eba9ecffab8f7f3dbc8"}},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111346981111107, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f4f5896156c43c1a65c77e05490c683"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241205_062159-wq56ptxh</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/kazireyazulhasan-bangladesh-university-of-engineering-an/sentence-transformers/runs/wq56ptxh' target=\"_blank\">checkpoints/model</a></strong> to <a href='https://wandb.ai/kazireyazulhasan-bangladesh-university-of-engineering-an/sentence-transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/kazireyazulhasan-bangladesh-university-of-engineering-an/sentence-transformers' target=\"_blank\">https://wandb.ai/kazireyazulhasan-bangladesh-university-of-engineering-an/sentence-transformers</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/kazireyazulhasan-bangladesh-university-of-engineering-an/sentence-transformers/runs/wq56ptxh' target=\"_blank\">https://wandb.ai/kazireyazulhasan-bangladesh-university-of-engineering-an/sentence-transformers/runs/wq56ptxh</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [30/30 00:36, Epoch 30/30]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f791bf49e96440e2bb4403b94cb541f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"861d6d530fbf4871a990465854ccfd91"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"from sentence_transformers import util\n\n# Load fine-tuned model\nfine_tuned_model = SentenceTransformer(\"output/contrastive-mpnet\")\n\n# Test examples\nanchor = \"John went to Goa for vacation\"\nnegative = \"John went to for vacation\"\npositive = \"Goa\"\n\n# Compute embeddings\nemb_anchor = fine_tuned_model.encode(anchor, convert_to_tensor=True)\nemb_positive = fine_tuned_model.encode(positive, convert_to_tensor=True)\nemb_negative = fine_tuned_model.encode(negative, convert_to_tensor=True)\n\n# Compute cosine similarity\nsim_positive = util.cos_sim(emb_anchor, emb_positive)\nsim_negative = util.cos_sim(emb_anchor, emb_negative)\n\nprint(\"Similarity with positive:\", sim_positive.item())\nprint(\"Similarity with negative:\", sim_negative.item())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T06:22:42.896273Z","iopub.execute_input":"2024-12-05T06:22:42.896928Z","iopub.status.idle":"2024-12-05T06:22:43.451688Z","shell.execute_reply.started":"2024-12-05T06:22:42.896876Z","shell.execute_reply":"2024-12-05T06:22:43.450628Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cc93c899cae4aca854cc4788864c6a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca0237ff981646fcb25dbd8619e1d909"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6926a56213a446c5ae7a80eca9787c36"}},"metadata":{}},{"name":"stdout","text":"Similarity with positive: 0.851870059967041\nSimilarity with negative: 0.43118396401405334\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from sentence_transformers import losses\n\n# Prepare data: Only anchor-positive pairs are needed\ndata = [\n    {\"anchor\": \"Bali\", \"positive\": \"John went to Bali for vacation\"},\n    {\"anchor\": \"Paris\", \"positive\": \"John went to Paris for vacation\"}\n]\n\n# Convert to InputExample format\ntrain_examples = [\n    InputExample(texts=[item[\"anchor\"], item[\"positive\"]])\n    for item in data\n]\n\n# Define the dataloader\ntrain_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n\n# Define the InfoNCE (MultipleNegativesRankingLoss) loss function\ntrain_loss = losses.MultipleNegativesRankingLoss(model)\n\n# Fine-tune the model\nmodel.fit(\n    train_objectives=[(train_dataloader, train_loss)],\n    epochs=30,\n    warmup_steps=100,\n    output_path=\"output/infonce-mpnet\"\n)\n\n# Load the fine-tuned model\nfine_tuned_model = SentenceTransformer(\"output/infonce-mpnet\")\n\n# Test examples\nanchor = \"John went to Goa for vacation\"\nnegative = \"John went to for vacation\"\npositive = \"Goa\"\n\n# Compute embeddings\nemb_anchor = fine_tuned_model.encode(anchor, convert_to_tensor=True)\nemb_positive = fine_tuned_model.encode(positive, convert_to_tensor=True)\nemb_negative = fine_tuned_model.encode(negative, convert_to_tensor=True)\n\n# Compute cosine similarity\nsim_positive = util.cos_sim(emb_anchor, emb_positive)\nsim_negative = util.cos_sim(emb_anchor, emb_negative)\n\nprint(\"Similarity with positive:\", sim_positive.item())\nprint(\"Similarity with negative:\", sim_negative.item())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T06:22:43.453214Z","iopub.execute_input":"2024-12-05T06:22:43.453634Z","iopub.status.idle":"2024-12-05T06:23:15.516873Z","shell.execute_reply.started":"2024-12-05T06:22:43.453588Z","shell.execute_reply":"2024-12-05T06:23:15.515750Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [30/30 00:28, Epoch 30/30]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b5a4cb7b65445ea85c36b2863b775c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"895c803485d34067b95055cc54ac0dce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6dab743eca314620b8f22896095f614b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f440756d37b4f9f8bcc49bc4f78d3ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f9c4d8b7fde4b14be1ddce7b59d5395"}},"metadata":{}},{"name":"stdout","text":"Similarity with positive: 0.8516236543655396\nSimilarity with negative: 0.42966514825820923\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"anchor = \"John went to Bali for vacation\"\nnegative = \"John went to Bahrain for vacation\"\npositive = \"Indonesia\"\n\n# Compute embeddings\nemb_anchor = fine_tuned_model.encode(anchor, convert_to_tensor=True)\nemb_positive = fine_tuned_model.encode(positive, convert_to_tensor=True)\nemb_negative = fine_tuned_model.encode(negative, convert_to_tensor=True)\n\n# Compute cosine similarity\nsim_positive = util.cos_sim(emb_anchor, emb_positive)\nsim_negative = util.cos_sim(emb_anchor, emb_negative)\n\nprint(\"Similarity with positive:\", sim_positive.item())\nprint(\"Similarity with negative:\", sim_negative.item())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T06:25:09.317780Z","iopub.execute_input":"2024-12-05T06:25:09.318222Z","iopub.status.idle":"2024-12-05T06:25:09.556733Z","shell.execute_reply.started":"2024-12-05T06:25:09.318187Z","shell.execute_reply":"2024-12-05T06:25:09.555387Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4288951b8e4408b882f76294740e13e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa09dec3606e402e972c7804420fd9ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cf57a67fe9142ab9493b3a1e620134d"}},"metadata":{}},{"name":"stdout","text":"Similarity with positive: 0.5959672331809998\nSimilarity with negative: 0.1831170618534088\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}