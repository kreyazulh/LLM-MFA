{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers langchain scikit-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T12:14:07.017835Z","iopub.execute_input":"2024-11-14T12:14:07.018356Z","iopub.status.idle":"2024-11-14T12:14:27.716378Z","shell.execute_reply.started":"2024-11-14T12:14:07.018303Z","shell.execute_reply":"2024-11-14T12:14:27.715149Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nCollecting langchain\n  Downloading langchain-0.3.7-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.5)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nCollecting langchain-core<0.4.0,>=0.3.15 (from langchain)\n  Downloading langchain_core-0.3.18-py3-none-any.whl.metadata (6.3 kB)\nCollecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n  Downloading langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\nCollecting langsmith<0.2.0,>=0.1.17 (from langchain)\n  Downloading langsmith-0.1.143-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.9.2)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.3.0)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\nCollecting packaging>=20.0 (from transformers)\n  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.4)\nCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.4.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (2.4)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.0)\nDownloading langchain-0.3.7-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading langchain_core-0.3.18-py3-none-any.whl (409 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.3/409.3 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\nDownloading langsmith-0.1.143-py3-none-any.whl (306 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.0/307.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, requests-toolbelt, langsmith, langchain-core, langchain-text-splitters, langchain\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: requests-toolbelt\n    Found existing installation: requests-toolbelt 0.10.1\n    Uninstalling requests-toolbelt-0.10.1:\n      Successfully uninstalled requests-toolbelt-0.10.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.2 which is incompatible.\njupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nthinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-0.3.7 langchain-core-0.3.18 langchain-text-splitters-0.3.2 langsmith-0.1.143 packaging-24.2 requests-toolbelt-1.0.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM, pipeline\nfrom sklearn.neighbors import NearestNeighbors\nimport numpy as np\n\n# Example employee data\nemployee_data = [\n    {\"id\": 1, \"info\": \"John loves pets, has a golden retriever named Max, and enjoys volunteering at the local animal shelter on weekends. He visited Bali last summer and stayed at the Serenity Resort. During his trip, he took a surfing lesson, tried local Balinese cuisine, and attended a cultural dance event. John works as a software engineer in the finance department and has been with the company since 2018. He attended Stanford University, where he studied Computer Science. John’s hobbies include hiking, reading science fiction novels, and playing the guitar. He has a younger sister, Emma, who lives in Boston. Recently, he went on a business trip to Tokyo and enjoyed visiting the Tokyo Tower and trying authentic sushi.\"},\n    {\"id\": 2, \"info\": \"Sarah is from NY, visited family in Canada recently\"}\n]\n\n# Load embedding model (distilbert-base-uncased)\nembedding_model_name = \"distilbert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(embedding_model_name)\nembedding_model = AutoModel.from_pretrained(embedding_model_name)\n\n# Function to embed text data\ndef embed_text(text):\n    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n    outputs = embedding_model(**inputs)\n    return outputs.last_hidden_state.mean(dim=1).detach().numpy()\n\n# Create embeddings for employee data\nembeddings = np.vstack([embed_text(entry[\"info\"]) for entry in employee_data])\n\n# Index embeddings using NearestNeighbors\nindex = NearestNeighbors(n_neighbors=1, metric=\"cosine\").fit(embeddings)\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-14T12:14:27.719117Z","iopub.execute_input":"2024-11-14T12:14:27.719909Z","iopub.status.idle":"2024-11-14T12:14:55.356730Z","shell.execute_reply.started":"2024-11-14T12:14:27.719851Z","shell.execute_reply":"2024-11-14T12:14:55.355603Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00e7bdf560194e3fb199dd755815a7d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"985d3f22eed742c280e63f3f752f9650"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1079a6074b04915b2ae7f6543002e42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17e8da34ca844997ab18eba9e440e4d6"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2cf51c0a9da4e76a515a28e842d684b"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import os\n\n# Replace 'YOUR_HUGGINGFACE_TOKEN' with the token you generated\nos.environ[\"HUGGINGFACE_TOKEN\"] = \"your token here\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T12:14:55.358309Z","iopub.execute_input":"2024-11-14T12:14:55.359326Z","iopub.status.idle":"2024-11-14T12:14:55.364877Z","shell.execute_reply.started":"2024-11-14T12:14:55.359277Z","shell.execute_reply":"2024-11-14T12:14:55.363714Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!pip install langchain-community","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T12:14:55.368265Z","iopub.execute_input":"2024-11-14T12:14:55.368758Z","iopub.status.idle":"2024-11-14T12:15:13.419254Z","shell.execute_reply.started":"2024-11-14T12:14:55.368704Z","shell.execute_reply":"2024-11-14T12:15:13.417569Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting langchain-community\n  Downloading langchain_community-0.3.7-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (6.0.2)\nRequirement already satisfied: SQLAlchemy<2.0.36,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (3.9.5)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.6.7)\nCollecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nRequirement already satisfied: langchain<0.4.0,>=0.3.7 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.3.7)\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.17 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.3.18)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.125 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.1.143)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (1.26.4)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (8.3.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nRequirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.7->langchain-community) (0.3.2)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.7->langchain-community) (2.9.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.17->langchain-community) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.17->langchain-community) (24.2)\nRequirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.17->langchain-community) (4.12.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.4)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\nRequirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<2.0.36,>=1.4->langchain-community) (3.0.3)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (4.4.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.17->langchain-community) (2.4)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain-community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain-community) (2.23.4)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.2.0)\nDownloading langchain_community-0.3.7-py3-none-any.whl (2.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\nInstalling collected packages: httpx-sse, pydantic-settings, langchain-community\nSuccessfully installed httpx-sse-0.4.0 langchain-community-0.3.7 pydantic-settings-2.6.1\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Load generation model (Llama 2 or similar) directly for text generation\ngeneration_model_name = \"meta-llama/Llama-2-7b-chat-hf\"  # Substitute with accessible model if needed\ngen_tokenizer = AutoTokenizer.from_pretrained(generation_model_name, use_auth_token=os.environ[\"HUGGINGFACE_TOKEN\"])\ngen_model = AutoModelForCausalLM.from_pretrained(generation_model_name, use_auth_token=os.environ[\"HUGGINGFACE_TOKEN\"])\ngeneration_pipeline = pipeline(\"text-generation\", model=gen_model, tokenizer=gen_tokenizer)\n\n# Retrieval function\ndef retrieve_context(query, top_k=1):\n    query_embedding = embed_text(query)\n    distances, indices = index.kneighbors(query_embedding, n_neighbors=top_k)\n    return [employee_data[idx]['info'] for idx in indices[0]]\n\n# Function to generate a response\ndef generate_response(query):\n    # Retrieve relevant context\n    context = retrieve_context(query, top_k=1)[0]\n    \n    # Combine context and query for input\n    prompt = f\"Context: {context}\\nQuestion: {query}\\nAnswer:\"\n    \n    # Generate answer with generation pipeline\n    result = generation_pipeline(prompt, max_length=300, do_sample=True)\n    \n    # Debug print to inspect the result structure\n    print(\"Result from generation pipeline:\", result)\n    \n    # Check the output structure and access text accordingly\n    if isinstance(result, list) and \"generated_text\" in result[0]:\n        return result[0][\"generated_text\"]\n    elif isinstance(result, list):\n        return result[0]\n    else:\n        return result\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T12:15:13.421213Z","iopub.execute_input":"2024-11-14T12:15:13.421626Z","iopub.status.idle":"2024-11-14T12:17:10.884974Z","shell.execute_reply.started":"2024-11-14T12:15:13.421582Z","shell.execute_reply":"2024-11-14T12:17:10.883890Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:796: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fda97b5757d4e1d897d1e930011190c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31d2ef0690a64bd0a65abbf514f0c061"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31ccd51602fd49d7ba1580779f1ec08f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30792df8f5a140da983867c991a018c4"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19d49e13b8ff48c4b38496e669f1d8fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63b2eac1a75541dab66e63aff45677a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"694f905bd8ad4b37aae7cf6fafcbb65b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc95fa51f0a14b80811256678f028bd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d15255167e444bab5fd8437dbd5d738"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11a836b8f3b547a6876fb2a26d2c9cfa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a040659bcf543c39e664e33d7b6853a"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"query = \"Where did John go on his last vacation?\"\nresponse = generate_response(query)\nprint(\"Response:\", response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T12:17:10.886541Z","iopub.execute_input":"2024-11-14T12:17:10.886961Z","iopub.status.idle":"2024-11-14T12:17:59.099696Z","shell.execute_reply.started":"2024-11-14T12:17:10.886918Z","shell.execute_reply":"2024-11-14T12:17:59.098462Z"}},"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nStarting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n","output_type":"stream"},{"name":"stdout","text":"Result from generation pipeline: [{'generated_text': 'Context: John loves pets, has a golden retriever named Max, and enjoys volunteering at the local animal shelter on weekends. He visited Bali last summer and stayed at the Serenity Resort. During his trip, he took a surfing lesson, tried local Balinese cuisine, and attended a cultural dance event. John works as a software engineer in the finance department and has been with the company since 2018. He attended Stanford University, where he studied Computer Science. John’s hobbies include hiking, reading science fiction novels, and playing the guitar. He has a younger sister, Emma, who lives in Boston. Recently, he went on a business trip to Tokyo and enjoyed visiting the Tokyo Tower and trying authentic sushi.\\nQuestion: Where did John go on his last vacation?\\nAnswer: According to the passage, John went on his last vacation to Bali.'}]\nResponse: Context: John loves pets, has a golden retriever named Max, and enjoys volunteering at the local animal shelter on weekends. He visited Bali last summer and stayed at the Serenity Resort. During his trip, he took a surfing lesson, tried local Balinese cuisine, and attended a cultural dance event. John works as a software engineer in the finance department and has been with the company since 2018. He attended Stanford University, where he studied Computer Science. John’s hobbies include hiking, reading science fiction novels, and playing the guitar. He has a younger sister, Emma, who lives in Boston. Recently, he went on a business trip to Tokyo and enjoyed visiting the Tokyo Tower and trying authentic sushi.\nQuestion: Where did John go on his last vacation?\nAnswer: According to the passage, John went on his last vacation to Bali.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!pip install sentence-transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T12:17:59.101172Z","iopub.execute_input":"2024-11-14T12:17:59.101574Z","iopub.status.idle":"2024-11-14T12:18:18.412806Z","shell.execute_reply.started":"2024-11-14T12:17:59.101534Z","shell.execute_reply":"2024-11-14T12:18:18.411175Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting sentence-transformers\n  Downloading sentence_transformers-3.3.0-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.45.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.4.0+cpu)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.25.1)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nDownloading sentence_transformers-3.3.0-py3-none-any.whl (268 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.7/268.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-3.3.0\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Load Sentence Transformer model\nembedding_model_name = \"hkunlp/instructor-large\"  # Or use another model optimized for semantic similarity\nsentence_model = SentenceTransformer(embedding_model_name)\n\n# Updated function to calculate risk score with sentence embeddings\ndef calculate_risk_score(expected_answer, user_answer):\n    # Generate embeddings for both expected and user-provided answers\n    expected_embedding = sentence_model.encode([expected_answer])\n    user_embedding = sentence_model.encode([user_answer])\n    \n    # Calculate cosine similarity using sentence embeddings\n    similarity_score = cosine_similarity(expected_embedding, user_embedding)[0][0]\n    \n    # Risk score is inversely related to similarity\n    risk_score = (1 - similarity_score) * 100\n    return risk_score\n\n# Example query and LLM-generated answer\nquery = \"Where did John go on his last vacation?\"\nexpected_answer = \"He went to Bali\"  # or generate_response(query) if using dynamic generation\n\n# User-provided answer\nuser_answer = \"Some place in Indonesia, Bali I guess\"  # Testing with a correct answer\n\n# Calculate risk score based on similarity\nrisk_score = calculate_risk_score(expected_answer, user_answer)\n\n# Decision based on threshold\nthreshold = 45  # Define a threshold; if risk score is higher, flag as suspicious\naccess_decision = \"Access Granted\" if risk_score < threshold else \"Access Denied\"\n\n# Output results\nprint(\"User Answer:\", user_answer)\nprint(\"Risk Score:\", risk_score)\nprint(\"Access Decision:\", access_decision)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T12:18:18.414754Z","iopub.execute_input":"2024-11-14T12:18:18.415577Z","iopub.status.idle":"2024-11-14T12:18:33.251393Z","shell.execute_reply.started":"2024-11-14T12:18:18.415524Z","shell.execute_reply":"2024-11-14T12:18:33.250076Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/461 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"247ba601826f47feb73e69c494f392bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d747c1e848c94b34a1bc0e6cb8fad797"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/66.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"632a2afb9f7e4ee98f513fe49bea69ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f937f5db8f84928b0c6aefad21f3577"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75b4915752834261b596bbecf3f9fb3a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.34G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cb38e2fee4d43fb9ac6baf0395bb90f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.41k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43b3d49181bb474ab1ea5322b4ba7f89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"653be214330f4b7184d4b2971a61be03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96e80ebaccbb4777b8aa73e2a3eae282"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53b353d8fa2e46a3a3094e9d7a7e7022"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/270 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60e22e5627c244448c2f3bc225f0c0e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"2_Dense/config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5047cbad991476fafff206bad5f051f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/3.15M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"291f497d725644459dda19870a7fa880"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ff82bb3c973436b8efa69e7906759ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b4e4289397e47cb81091c2cc29a765d"}},"metadata":{}},{"name":"stdout","text":"User Answer: Some place in Indonesia, Bali I guess\nRisk Score: 7.182079553604126\nAccess Decision: Access Granted\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# User-provided answer\nuser_answer = \"He went to Bali\"  # correct answer\n\n# Calculate risk score based on similarity\nrisk_score = calculate_risk_score(expected_answer, user_answer)\n\n# Decision based on threshold\nthreshold = 45  # Define a threshold; if risk score is higher, flag as suspicious\naccess_decision = \"Access Granted\" if risk_score < threshold else \"Access Denied\"\n\n# Output results\nprint(\"User Answer:\", user_answer)\nprint(\"Risk Score:\", risk_score)\nprint(\"Access Decision:\", access_decision)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T12:18:33.253116Z","iopub.execute_input":"2024-11-14T12:18:33.253918Z","iopub.status.idle":"2024-11-14T12:18:33.863387Z","shell.execute_reply.started":"2024-11-14T12:18:33.253862Z","shell.execute_reply":"2024-11-14T12:18:33.862044Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ad133b68e5f453ca6cf73a3dae2b423"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b32706ea3306462989e405cf701a38c8"}},"metadata":{}},{"name":"stdout","text":"User Answer: He went to Bali\nRisk Score: 0.0\nAccess Decision: Access Granted\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import hashlib\nimport time\nimport json\n\n# Example employee data\nemployee_data = [\n    {\"id\": 1, \"info\": \"John loves pets, has a golden retriever named Max, and enjoys volunteering at the local animal shelter on weekends. He visited Bali last summer and stayed at the Serenity Resort. During his trip, he took a surfing lesson, tried local Balinese cuisine, and attended a cultural dance event. John works as a software engineer in the finance department and has been with the company since 2018. He attended Stanford University, where he studied Computer Science. John’s hobbies include hiking, reading science fiction novels, and playing the guitar. He has a younger sister, Emma, who lives in Boston. Recently, he went on a business trip to Tokyo and enjoyed visiting the Tokyo Tower and trying authentic sushi.\"},\n    {\"id\": 2, \"info\": \"Sarah is from NY, visited family in Canada recently\"}\n]\n\n# Blockchain structure to store hashes of employee data\nclass Block:\n    def __init__(self, index, data_hash, previous_hash):\n        self.index = index\n        self.timestamp = time.time()\n        self.data_hash = data_hash  # Hash of the employee data\n        self.previous_hash = previous_hash  # Link to the previous block's hash\n        self.hash = self.compute_hash()  # Hash of the current block\n\n    def compute_hash(self):\n        block_string = json.dumps({\n            \"index\": self.index,\n            \"timestamp\": self.timestamp,\n            \"data_hash\": self.data_hash,\n            \"previous_hash\": self.previous_hash\n        }, sort_keys=True).encode()\n        return hashlib.sha256(block_string).hexdigest()\n\nclass Blockchain:\n    def __init__(self):\n        self.chain = []\n        self.create_genesis_block()\n\n    def create_genesis_block(self):\n        # Create the first block in the blockchain\n        genesis_block = Block(0, \"0\", \"0\")\n        self.chain.append(genesis_block)\n\n    def add_block(self, data_hash):\n        previous_hash = self.chain[-1].hash\n        new_block = Block(len(self.chain), data_hash, previous_hash)\n        self.chain.append(new_block)\n\n    def is_chain_valid(self):\n        # Check if the blockchain is valid\n        for i in range(1, len(self.chain)):\n            current_block = self.chain[i]\n            previous_block = self.chain[i - 1]\n            # Check if current block's hash is valid\n            if current_block.hash != current_block.compute_hash():\n                return False\n            # Check if the block links are consistent\n            if current_block.previous_hash != previous_block.hash:\n                return False\n        return True\n\n# Function to hash employee data\ndef hash_employee_data(employee):\n    employee_string = json.dumps(employee, sort_keys=True).encode()\n    return hashlib.sha256(employee_string).hexdigest()\n\n# Initialize blockchain\nblockchain = Blockchain()\n\n# Add employee data to blockchain as hashed entries\nfor employee in employee_data:\n    data_hash = hash_employee_data(employee)\n    blockchain.add_block(data_hash)\n\n# Check blockchain integrity function\ndef check_integrity(new_data):\n    \"\"\"Verify the data against stored blockchain hashes\"\"\"\n    data_hash = hash_employee_data(new_data)\n    # Check if hash matches any existing block in the blockchain\n    for block in blockchain.chain:\n        if block.data_hash == data_hash:\n            print(\"Data integrity confirmed.\")\n            return True\n    print(\"Data has been tampered with or is unverified.\")\n    return False\n\n# Example: Checking integrity of data\ntampered_data = {\"id\": 1, \"info\": \"John loves cats, has a golden retriever named Max, and enjoys volunteering at the local animal shelter on weekends. He visited Bali last summer and stayed at the Serenity Resort. During his trip, he took a surfing lesson, tried local Balinese cuisine, and attended a cultural dance event. John works as a software engineer in the finance department and has been with the company since 2018. He attended Stanford University, where he studied Computer Science. John’s hobbies include hiking, reading science fiction novels, and playing the guitar. He has a younger sister, Emma, who lives in Boston. Recently, he went on a business trip to Tokyo and enjoyed visiting the Tokyo Tower and trying authentic sushi.\"}  # Tampered entry\ncheck_integrity(tampered_data)  # Should print warning about tampering\n\n# Example: Checking integrity of original data\ncheck_integrity(employee_data[0])  # Should confirm integrity\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T12:18:33.868465Z","iopub.execute_input":"2024-11-14T12:18:33.868910Z","iopub.status.idle":"2024-11-14T12:18:33.897504Z","shell.execute_reply.started":"2024-11-14T12:18:33.868858Z","shell.execute_reply":"2024-11-14T12:18:33.896135Z"}},"outputs":[{"name":"stdout","text":"Data has been tampered with or is unverified.\nData integrity confirmed.\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# Define function to dynamically generate questions\ndef generate_dynamic_question(employee_info, risk_level):\n    # Define prompt based on risk level and employee info\n    prompt = f\"Based on the following information about an employee: '{employee_info}', generate a {risk_level}-risk question for verification purposes. The answer must be present in employee info.\"\n    \n    # Generate question using the pipeline\n    result = generation_pipeline(prompt, max_length=300, do_sample=True)\n    \n    # Retrieve generated text\n    if isinstance(result, list) and \"generated_text\" in result[0]:\n        question = result[0][\"generated_text\"].strip()\n    else:\n        question = result[0] if isinstance(result, list) else result\n\n    return question\n\n# Function to determine question difficulty based on risk score\ndef get_question_difficulty(risk_score):\n    if risk_score < 10:\n        return \"low\"\n    elif risk_score < 15:\n        return \"medium\"\n    else:\n        return \"high\"\n\n# Example response generation function integrating with risk score\ndef generate_risk_aware_question(user_answer, expected_answer, employee_info):\n    # Calculate risk score based on similarity\n    expected_embedding = sentence_model.encode([expected_answer])\n    user_embedding = sentence_model.encode([user_answer])\n    \n    # Calculate cosine similarity using sentence embeddings\n    similarity_score = cosine_similarity(expected_embedding, user_embedding)[0][0]\n    \n    # Risk score is inversely related to similarity\n    risk_score = (1 - similarity_score) * 100\n\n    # Select question difficulty based on risk score\n    difficulty = get_question_difficulty(risk_score)\n    \n    # Dynamically generate question based on employee data and risk level\n    question = generate_dynamic_question(employee_info, difficulty)\n\n    # Output for testing\n    print(f\"Risk Score: {risk_score:.2f} - Question Difficulty: {difficulty.capitalize()}\")\n    print(f\"Next Question: {question}\")\n\n    return question, risk_score\n\n# Example Usage\nquery = \"Where did John go on his last vacation?\"\nexpected_answer = \"Bali\"\nuser_answer = \"He went to Paris\"  # Incorrect answer, triggering higher risk\nemployee_info = \"John loves pets, has a golden retriever named Max, and enjoys volunteering at the local animal shelter on weekends. He visited Bali last summer and stayed at the Serenity Resort. During his trip, he took a surfing lesson, tried local Balinese cuisine, and attended a cultural dance event. John works as a software engineer in the finance department and has been with the company since 2018. He attended Stanford University, where he studied Computer Science. John’s hobbies include hiking, reading science fiction novels, and playing the guitar. He has a younger sister, Emma, who lives in Boston. Recently, he went on a business trip to Tokyo and enjoyed visiting the Tokyo Tower and trying authentic sushi.\"\n\nnext_question, current_risk_score = generate_risk_aware_question(user_answer, expected_answer, employee_info)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T12:18:33.899816Z","iopub.execute_input":"2024-11-14T12:18:33.900451Z","iopub.status.idle":"2024-11-14T12:19:25.614266Z","shell.execute_reply.started":"2024-11-14T12:18:33.900375Z","shell.execute_reply":"2024-11-14T12:19:25.612951Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"954214adf2be4b9d9b229d76b05fdf1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48a33a9e016b4fc7ac156198added092"}},"metadata":{}},{"name":"stdout","text":"Risk Score: 19.56 - Question Difficulty: High\nNext Question: Based on the following information about an employee: 'John loves pets, has a golden retriever named Max, and enjoys volunteering at the local animal shelter on weekends. He visited Bali last summer and stayed at the Serenity Resort. During his trip, he took a surfing lesson, tried local Balinese cuisine, and attended a cultural dance event. John works as a software engineer in the finance department and has been with the company since 2018. He attended Stanford University, where he studied Computer Science. John’s hobbies include hiking, reading science fiction novels, and playing the guitar. He has a younger sister, Emma, who lives in Boston. Recently, he went on a business trip to Tokyo and enjoyed visiting the Tokyo Tower and trying authentic sushi.', generate a high-risk question for verification purposes. The answer must be present in employee info.\nWhat is the name of the local animal shelter where John volunteers on weekends?\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"def agentic_rag(query, risk_threshold=15):\n    \"\"\"Retrieves context, generates dynamic questions, and refines based on user responses autonomously.\"\"\"\n    \n    # Initial retrieval context\n    context = retrieve_context(query, top_k=1)[0]\n    history = []  # To store question/response history\n\n    # Generate initial response\n    prompt = f\"Context: {context}\\nQuestion: {query}\\nAnswer:\"\n    initial_response = generation_pipeline(prompt, max_length=300, do_sample=True)[0][\"generated_text\"]\n    response = initial_response  # Initialize response with initial response\n\n    # Simulate user answer and calculate risk\n    user_answer = \"Simulated User Answer\"\n    risk_score = calculate_risk_score(initial_response, user_answer)\n\n    # Dynamic adjustment of query flow based on risk score\n    while risk_score > risk_threshold:\n        # Adjust query difficulty for high-risk score\n        refined_prompt = f\"Context: {context}\\nGiven higher risk detected, please verify:\\n{query}\\nAnswer:\"\n        response = generation_pipeline(refined_prompt, max_length=300, do_sample=True)[0][\"generated_text\"]\n        \n        # Log and re-evaluate\n        history.append((query, response))\n        user_answer = \"Bali\"  # Simulate hacker answer\n        risk_score = calculate_risk_score(response, user_answer)\n\n    return response, risk_score, history\n\n# Example Query Execution with Agentic RAG\nquery = \"Where did John go on his last vacation?\"\nresponse, final_risk_score, conversation_history = agentic_rag(query)\nprint(\"Final Response:\", response)\nprint(\"Final Risk Score:\", final_risk_score)\nprint(\"Conversation History:\", conversation_history)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T12:57:19.866683Z","iopub.execute_input":"2024-11-14T12:57:19.867135Z","iopub.status.idle":"2024-11-14T12:58:39.013305Z","shell.execute_reply.started":"2024-11-14T12:57:19.867089Z","shell.execute_reply":"2024-11-14T12:58:39.011818Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"906f7b0134fd465c8fcd13838f632efb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6049a69016c48d39b2789b2265fb291"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4fe64796e34426fb1daa4384f1c5acb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94921f54cde54e378f09f2f632a9d610"}},"metadata":{}},{"name":"stdout","text":"Final Response: Context: John loves pets, has a golden retriever named Max, and enjoys volunteering at the local animal shelter on weekends. He visited Bali last summer and stayed at the Serenity Resort. During his trip, he took a surfing lesson, tried local Balinese cuisine, and attended a cultural dance event. John works as a software engineer in the finance department and has been with the company since 2018. He attended Stanford University, where he studied Computer Science. John’s hobbies include hiking, reading science fiction novels, and playing the guitar. He has a younger sister, Emma, who lives in Boston. Recently, he went on a business trip to Tokyo and enjoyed visiting the Tokyo Tower and trying authentic sushi.\nGiven higher risk detected, please verify:\nWhere did John go on his last vacation?\nAnswer: Bali.\nFinal Risk Score: 14.834016561508179\nConversation History: [('Where did John go on his last vacation?', 'Context: John loves pets, has a golden retriever named Max, and enjoys volunteering at the local animal shelter on weekends. He visited Bali last summer and stayed at the Serenity Resort. During his trip, he took a surfing lesson, tried local Balinese cuisine, and attended a cultural dance event. John works as a software engineer in the finance department and has been with the company since 2018. He attended Stanford University, where he studied Computer Science. John’s hobbies include hiking, reading science fiction novels, and playing the guitar. He has a younger sister, Emma, who lives in Boston. Recently, he went on a business trip to Tokyo and enjoyed visiting the Tokyo Tower and trying authentic sushi.\\nGiven higher risk detected, please verify:\\nWhere did John go on his last vacation?\\nAnswer: Bali.')]\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}